{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "REDUCTION_FILTERS = {\n",
    "    'Inception-v4' : {\n",
    "        'k' : 192,\n",
    "        'l' : 224,\n",
    "        'm' : 256,\n",
    "        'n' : 384\n",
    "    },\n",
    "    'Inception-ResNet-v2' : {\n",
    "        'k' : 256,\n",
    "        'l' : 256,\n",
    "        'm' : 384,\n",
    "        'n' : 384\n",
    "    }\n",
    "}\n",
    "WEIGHTS_TYPE = 'Inception-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_bn(filters, kernel_size, padding='v', strides=1, activation='relu', **kwargs):\n",
    "    padding = 'valid' if padding == 'v' else 'same'\n",
    "    x, y = kernel_size.split('x')\n",
    "    kernel_size = [int(x), int(y)]\n",
    "    return keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,**kwargs),\n",
    "        keras.layers.BatchNormalization(scale=False),\n",
    "        keras.layers.Activation(activation),\n",
    "    ])\n",
    "\n",
    "def conv2d(filters, kernel_size, padding='v', strides=1, activation='relu', **kwargs):\n",
    "    padding = 'valid' if padding == 'v' else 'same'\n",
    "    x, y = kernel_size.split('x')\n",
    "    kernel_size = [int(x), int(y)]\n",
    "    return keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,activation=activation, **kwargs)\n",
    "\n",
    "\n",
    "def max_pool2d(pool_size='2x2', padding='v', strides=1):\n",
    "    x, y = pool_size.split('x')\n",
    "    pool_size = [int(x), int(y)]\n",
    "    padding = 'valid' if padding == 'v' else 'same'\n",
    "    return keras.layers.MaxPool2D(pool_size=pool_size, strides=strides, padding=padding)\n",
    "\n",
    "def avg_pool2d(pool_size='2x2', padding='v', strides=1):\n",
    "    x, y = pool_size.split('x')\n",
    "    pool_size = [int(x), int(y)]\n",
    "    padding = 'valid' if padding == 'v' else 'same'\n",
    "    return keras.layers.AveragePooling2D(pool_size=pool_size, strides=strides, padding=padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        #conv 32 3x3 2 v\n",
    "        #conv 32 3x3 v\n",
    "        #conv 64 3x3 s\n",
    "        #max pool 3x3 v + conv 96 3x3 2 v\n",
    "        #conv 64 1x1 s   / \n",
    "        #conv 64 7x1 s / \n",
    "        #conv 64 1x7 s / conv 64 1x1 s\n",
    "        #conv 96 3x3 s + conv 96 3x3 s\n",
    "        #conv 192 3x3 v / max pool 2 v\n",
    "        \n",
    "                                               #299x299x3\n",
    "        self.conv1 = conv2d_bn(32, '3x3', 'v', 2) #149x149x3\n",
    "        self.conv2 = conv2d_bn(32, '3x3', 'v', 1) #147x147x3\n",
    "        self.conv3 = conv2d_bn(64, '3x3', 's', 1) #147x147x3\n",
    "\n",
    "        self.max_pool4_1 = max_pool2d('3x3', 'v', 2) #1\n",
    "        self.conv4_2 = conv2d_bn(32, '3x3', 'v', 2)\n",
    "        \n",
    "        self.concat5 = keras.layers.Concatenate(axis=-1)\n",
    "        \n",
    "        self.conv6_1 = conv2d_bn(64, '1x1', 's', 1)\n",
    "        self.conv6_2 = conv2d_bn(64, '7x1', 's', 1)\n",
    "        self.conv6_3 = conv2d_bn(96, '1x7', 's', 1)\n",
    "        self.conv6_4 = conv2d_bn(96, '3x3', 'v', 1)\n",
    "\n",
    "        self.conv7_1 = conv2d_bn(64, '1x1', 's', 1)\n",
    "        self.conv7_2 = conv2d_bn(96, '3x3', 'v', 1)\n",
    "\n",
    "        self.concat8 = keras.layers.Concatenate(axis=-1)\n",
    "\n",
    "        self.conv9_1 = conv2d_bn(192, '3x3', 'v', 2)\n",
    "        self.max_pool9_2 = max_pool2d('2x2', 'v', 2)\n",
    "\n",
    "        self.concat10 = keras.layers.Concatenate(axis=-1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        Z = self.conv1(Z)\n",
    "        Z = self.conv2(Z)\n",
    "        Z = self.conv3(Z)\n",
    "        Z_1 = self.max_pool4_1(Z)\n",
    "        Z_2 = self.conv4_2(Z)\n",
    "        Z = self.concat5([Z_1, Z_2])\n",
    "\n",
    "        Z_1 = self.conv6_1(Z)\n",
    "        Z_1 = self.conv6_2(Z_1)\n",
    "        Z_1 = self.conv6_3(Z_1)\n",
    "        Z_1 = self.conv6_4(Z_1)\n",
    "\n",
    "        Z_2 = self.conv7_1(Z)\n",
    "        Z_2 = self.conv7_2(Z_2)\n",
    "\n",
    "        Z = self.concat8([Z_1, Z_2])\n",
    "        \n",
    "        Z_1 = self.conv9_1(Z)\n",
    "        Z_2 = self.max_pool9_2(Z)\n",
    "\n",
    "        return self.concat10([Z_1, Z_2])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:12:13.786304: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-04 15:12:13.786737: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "stem (Stem)                  (None, 35, 35, 384)       604256    \n",
      "=================================================================\n",
      "Total params: 604,256\n",
      "Trainable params: 602,592\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=[299, 299, 3])\n",
    "stem_module = Stem()\n",
    "stem_outputs = stem_module(inputs)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=stem_outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReductionA(keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.max_pool1 = max_pool2d('3x3', 'v', 2)\n",
    "\n",
    "        self.conv2 = conv2d_bn(filters['n'], '3x3', 'v', 2)\n",
    "        \n",
    "        self.conv3_1 = conv2d_bn(filters['k'], '1x1', 's', 1)\n",
    "        self.conv3_2 = conv2d_bn(filters['l'], '3x3', 's', 1)\n",
    "        self.conv3_3 = conv2d_bn(filters['m'], '3x3', 'v', 2)\n",
    "\n",
    "        self.concat = keras.layers.Concatenate(axis=-1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        Z = inputs\n",
    "\n",
    "        Z_1 = self.max_pool1(Z)\n",
    "\n",
    "        Z_2 = self.conv2(Z)\n",
    "\n",
    "        Z_3 = self.conv3_1(Z)\n",
    "        Z_3 = self.conv3_2(Z_3)\n",
    "        Z_3 = self.conv3_3(Z_3)\n",
    "\n",
    "        return self.concat([Z_1, Z_2, Z_3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionA(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.avg_pool_1_1 = avg_pool2d('2x2', 's', 1)\n",
    "        self.conv1_2 = conv2d_bn(96, '1x1', 's', 1)\n",
    "        \n",
    "        self.conv2 = conv2d_bn(96, '1x1', 's', 1)\n",
    "        \n",
    "        self.conv3_1 = conv2d_bn(64, '1x1', 's', 1)\n",
    "        self.conv3_2 = conv2d_bn(96, '3x3', 's', 1)\n",
    "\n",
    "        self.conv4_1 = conv2d_bn(64, '1x1', 's', 1)\n",
    "        self.conv4_2 = conv2d_bn(96, '3x3', 's', 1)\n",
    "        self.conv4_3 = conv2d_bn(96, '3x3', 's', 1)\n",
    "\n",
    "        self.concat = keras.layers.Concatenate(axis=-1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        Z = inputs\n",
    "\n",
    "        Z_1 = self.avg_pool_1_1(Z)\n",
    "        Z_1 = self.conv1_2(Z_1)\n",
    "\n",
    "        Z_2 = self.conv2(Z)\n",
    "\n",
    "        Z_3 = self.conv3_1(Z)\n",
    "        Z_3 = self.conv3_2(Z_3)\n",
    "\n",
    "        Z_4 = self.conv4_1(Z)\n",
    "        Z_4 = self.conv4_2(Z_4)\n",
    "        Z_4 = self.conv4_3(Z_4)\n",
    "        \n",
    "        return keras.layers.Concatenate(axis=-1)([Z_1, Z_2, Z_3, Z_4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "stem_1 (Stem)                (None, 35, 35, 384)       604256    \n",
      "_________________________________________________________________\n",
      "inception_a (InceptionA)     (None, 35, 35, 384)       318848    \n",
      "=================================================================\n",
      "Total params: 923,104\n",
      "Trainable params: 920,224\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=[299, 299, 3])\n",
    "stem_module = Stem()\n",
    "stem_outputs = stem_module(inputs)\n",
    "\n",
    "inceptionA_module = InceptionA()\n",
    "inceptionA_outputs = inceptionA_module(stem_outputs)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=inceptionA_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionB(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.avg_pool_1_1 = avg_pool2d('2x2', 's', 1)\n",
    "        self.conv1_2 = conv2d_bn(128, '1x1', 's', 1)\n",
    "\n",
    "        self.conv2 = conv2d_bn(384, '1x1', 's', 1)\n",
    "\n",
    "        self.conv3_1 = conv2d_bn(192, '1x1', 's', 1)\n",
    "        self.conv3_2 = conv2d_bn(224, '7x1', 's', 1)\n",
    "        self.conv3_3 = conv2d_bn(256, '1x7', 's', 1)\n",
    "        \n",
    "        self.conv4_1 = conv2d_bn(192, '1x1', 's', 1)\n",
    "        self.conv4_2 = conv2d_bn(192, '1x7', 's', 1)\n",
    "        self.conv4_3 = conv2d_bn(224, '7x1', 's', 1)\n",
    "        self.conv4_4 = conv2d_bn(224, '1x7', 's', 1)\n",
    "        self.conv4_5 = conv2d_bn(256, '7x1', 's', 1)\n",
    "\n",
    "        self.concat = keras.layers.Concatenate(axis=-1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        Z = inputs\n",
    "\n",
    "        Z_1 = self.avg_pool_1_1(Z)\n",
    "        Z_1 = self.conv1_2(Z_1)\n",
    "\n",
    "        Z_2 = self.conv2(Z)\n",
    "\n",
    "        Z_3 = self.conv3_1(Z)\n",
    "        Z_3 = self.conv3_2(Z_3)\n",
    "        Z_3 = self.conv3_3(Z_3)\n",
    "\n",
    "        Z_4 = self.conv4_1(Z)\n",
    "        Z_4 = self.conv4_2(Z_4)\n",
    "        Z_4 = self.conv4_3(Z_4)\n",
    "        Z_4 = self.conv4_4(Z_4)\n",
    "        Z_4 = self.conv4_5(Z_4)\n",
    "    \n",
    "        return self.concat([Z_1, Z_2, Z_3, Z_3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "stem_2 (Stem)                (None, 35, 35, 384)       604256    \n",
      "_________________________________________________________________\n",
      "inception_a_1 (InceptionA)   (None, 35, 35, 384)       318848    \n",
      "_________________________________________________________________\n",
      "inception_a_2 (InceptionA)   (None, 35, 35, 384)       318848    \n",
      "_________________________________________________________________\n",
      "inception_a_3 (InceptionA)   (None, 35, 35, 384)       318848    \n",
      "_________________________________________________________________\n",
      "inception_a_4 (InceptionA)   (None, 35, 35, 384)       318848    \n",
      "_________________________________________________________________\n",
      "reduction_a (ReductionA)     (None, 17, 17, 1024)      2308224   \n",
      "_________________________________________________________________\n",
      "inception_b (InceptionB)     (None, 17, 17, 1024)      2940800   \n",
      "_________________________________________________________________\n",
      "inception_b_1 (InceptionB)   (None, 17, 17, 1024)      2940800   \n",
      "_________________________________________________________________\n",
      "inception_b_2 (InceptionB)   (None, 17, 17, 1024)      2940800   \n",
      "_________________________________________________________________\n",
      "inception_b_3 (InceptionB)   (None, 17, 17, 1024)      2940800   \n",
      "=================================================================\n",
      "Total params: 15,951,072\n",
      "Trainable params: 15,924,256\n",
      "Non-trainable params: 26,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=[299, 299, 3])\n",
    "stem_module = Stem()\n",
    "Z = stem_module(inputs)\n",
    "\n",
    "#4 x inception A\n",
    "inceptionA_modules = []\n",
    "for _ in range(4):\n",
    "    inceptionA_modules.append(InceptionA())\n",
    "for inceptionA_module in inceptionA_modules:\n",
    "    Z = inceptionA_module(Z)\n",
    "\n",
    "reductionA = ReductionA(REDUCTION_FILTERS[WEIGHTS_TYPE])\n",
    "Z = reductionA(Z)\n",
    "\n",
    "#7 x inceptioin B\n",
    "inceptionB_modules = []\n",
    "for _ in range(4):\n",
    "    inceptionB_modules.append(InceptionB())\n",
    "for inceptionB_module in inceptionB_modules:\n",
    "    Z = inceptionB_module(Z)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=Z)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReductionB(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.max_pool1 = max_pool2d('3x3', 'v', 2)\n",
    "\n",
    "        self.conv2_1 = conv2d_bn(192, '1x1', 's', 1)\n",
    "        self.conv2_2 = conv2d_bn(192, '3x3', 'v', 2)\n",
    "\n",
    "        self.conv3_1 = conv2d_bn(256, '1x1', 's', 1)\n",
    "        self.conv3_2 = conv2d_bn(256, '1x7', 's', 1)\n",
    "        self.conv3_3 = conv2d_bn(320, '7x1', 's', 1)\n",
    "        self.conv3_4 = conv2d_bn(320, '3x3', 'v', 2)\n",
    "\n",
    "        self.concat = keras.layers.Concatenate(axis=-1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        Z = inputs\n",
    "\n",
    "        Z_1 = self.max_pool1(Z)\n",
    "\n",
    "        Z_2 = self.conv2_1(Z)\n",
    "        Z_2 = self.conv2_2(Z_2)\n",
    "\n",
    "        Z_3 = self.conv3_1(Z)\n",
    "        Z_3 = self.conv3_2(Z_3)\n",
    "        Z_3 = self.conv3_3(Z_3)\n",
    "        Z_3 = self.conv3_4(Z_3)\n",
    "\n",
    "        return self.concat([Z_1, Z_2, Z_3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionC(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.arg_pool1_1 = avg_pool2d('2x2', 's', 1)\n",
    "        self.conv1_2 = conv2d_bn(256, '1x1', 's', 1)\n",
    "\n",
    "        self.conv2 = conv2d_bn(256, '1x1', 's', 1)\n",
    "        \n",
    "        self.conv3_1 = conv2d_bn(384, '1x1', 's', 1)\n",
    "        self.conv3_2_1 = conv2d_bn(256, '1x3', 's', 1)\n",
    "        self.conv3_2_2 = conv2d_bn(256, '3x1', 's', 1)\n",
    "\n",
    "        self.conv4_1 = conv2d_bn(384, '1x1', 's', 1)\n",
    "        self.conv4_2 = conv2d_bn(448, '1x3', 's', 1)\n",
    "        self.conv4_3 = conv2d_bn(512, '3x1', 's', 1)\n",
    "        self.conv4_4_1 = conv2d_bn(256, '3x1', 's', 1)\n",
    "        self.conv4_4_2 = conv2d_bn(256, '1x3', 's', 1)\n",
    "\n",
    "        self.concat = keras.layers.Concatenate(axis=-1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "\n",
    "        Z_1 = self.arg_pool1_1(Z)\n",
    "        Z_1 = self.conv1_2(Z_1)\n",
    "\n",
    "        Z_2 = self.conv2(Z)\n",
    "\n",
    "        Z_3 = self.conv3_1(Z)\n",
    "        Z_3_1 = self.conv3_2_1(Z_3)\n",
    "        Z_3_2 = self.conv3_2_2(Z_3)\n",
    "\n",
    "        Z_4 = self.conv4_1(Z)\n",
    "        Z_4 = self.conv4_2(Z_4)\n",
    "        Z_4 = self.conv4_3(Z_4)\n",
    "        Z_4_1 = self.conv4_4_1(Z_4)\n",
    "        Z_4_2 = self.conv4_4_2(Z_4)\n",
    "\n",
    "        return self.concat([Z_1, Z_2, Z_3_1, Z_3_2, Z_4_1, Z_4_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "stem_3 (Stem)                (None, 35, 35, 384)       604256    \n",
      "_________________________________________________________________\n",
      "inception_a_5 (InceptionA)   (None, 35, 35, 384)       318848    \n",
      "_________________________________________________________________\n",
      "inception_a_6 (InceptionA)   (None, 35, 35, 384)       318848    \n",
      "_________________________________________________________________\n",
      "inception_a_7 (InceptionA)   (None, 35, 35, 384)       318848    \n",
      "_________________________________________________________________\n",
      "inception_a_8 (InceptionA)   (None, 35, 35, 384)       318848    \n",
      "_________________________________________________________________\n",
      "reduction_a_1 (ReductionA)   (None, 17, 17, 1024)      2308224   \n",
      "_________________________________________________________________\n",
      "inception_b_4 (InceptionB)   (None, 17, 17, 1024)      2940800   \n",
      "_________________________________________________________________\n",
      "inception_b_5 (InceptionB)   (None, 17, 17, 1024)      2940800   \n",
      "_________________________________________________________________\n",
      "inception_b_6 (InceptionB)   (None, 17, 17, 1024)      2940800   \n",
      "_________________________________________________________________\n",
      "inception_b_7 (InceptionB)   (None, 17, 17, 1024)      2940800   \n",
      "_________________________________________________________________\n",
      "reduction_b (ReductionB)     (None, 8, 8, 1536)        2750464   \n",
      "_________________________________________________________________\n",
      "inception_c (InceptionC)     (None, 8, 8, 1536)        4559616   \n",
      "_________________________________________________________________\n",
      "inception_c_1 (InceptionC)   (None, 8, 8, 1536)        4559616   \n",
      "_________________________________________________________________\n",
      "inception_c_2 (InceptionC)   (None, 8, 8, 1536)        4559616   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 150)               230550    \n",
      "=================================================================\n",
      "Total params: 32,610,934\n",
      "Trainable params: 32,561,462\n",
      "Non-trainable params: 49,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=[299, 299, 3])\n",
    "stem_module = Stem()\n",
    "Z = stem_module(inputs)\n",
    "\n",
    "#4 x inception A\n",
    "inceptionA_modules = []\n",
    "for _ in range(4):\n",
    "    inceptionA_modules.append(InceptionA())\n",
    "for inceptionA_module in inceptionA_modules:\n",
    "    Z = inceptionA_module(Z)\n",
    "\n",
    "reductionA = ReductionA(REDUCTION_FILTERS[WEIGHTS_TYPE])\n",
    "Z = reductionA(Z)\n",
    "\n",
    "#7 x inceptioin B\n",
    "inceptionB_modules = []\n",
    "for _ in range(4):\n",
    "    inceptionB_modules.append(InceptionB())\n",
    "for inceptionB_module in inceptionB_modules:\n",
    "    Z = inceptionB_module(Z)\n",
    "\n",
    "reductionB = ReductionB()\n",
    "Z = reductionB(Z)\n",
    "\n",
    "#3 x inception C\n",
    "inceptionC_modules = []\n",
    "for _ in range(3):\n",
    "    inceptionC_modules.append(InceptionC())\n",
    "for inceptionC_module in inceptionC_modules:\n",
    "    Z = inceptionC_module(Z)\n",
    "\n",
    "Z = keras.layers.GlobalAveragePooling2D()(Z)\n",
    "Z = keras.layers.Dropout(0.8)(Z)\n",
    "outputs = keras.layers.Dense(150, activation='softmax')(Z)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "150507\n"
     ]
    }
   ],
   "source": [
    "#model.fit()\n",
    "import KFood_Dataset\n",
    "image_paths = KFood_Dataset.image_paths\n",
    "\n",
    "dataset = KFood_Dataset.make_kfood_dataset(image_paths, shuffle_buffer_size=10000, n_parse_threads=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:13:07.372027: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:13:07.847553: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:13:07.976161: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:13:08.047510: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:13:08.083183: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:13:08.825463: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:13:09.453224: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:13:15.983344: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  92/4704 [..............................] - ETA: 1:17:54 - loss: 2.7735"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:14:50.079417: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:14:50.079436: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: cHRM chunk does not match sRGB\n",
      "2022-01-04 15:14:50.080855: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:14:50.080866: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: cHRM chunk does not match sRGB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  96/4704 [..............................] - ETA: 1:17:59 - loss: 2.7533"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:14:54.273272: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  98/4704 [..............................] - ETA: 1:17:57 - loss: 2.7491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:14:56.302517: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:14:56.302532: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: cHRM chunk does not match sRGB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 122/4704 [..............................] - ETA: 1:17:21 - loss: 2.7358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:15:20.371736: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:15:20.371751: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: cHRM chunk does not match sRGB\n",
      "2022-01-04 15:15:20.374801: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:15:20.374812: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: cHRM chunk does not match sRGB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 125/4704 [..............................] - ETA: 1:17:16 - loss: 2.7318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:15:23.363960: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-01-04 15:15:23.363976: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: cHRM chunk does not match sRGB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 128/4704 [..............................] - ETA: 1:17:11 - loss: 2.7297"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:15:26.332457: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 222/4704 [>.............................] - ETA: 1:15:21 - loss: 2.7077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:17:00.729106: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 223/4704 [>.............................] - ETA: 1:15:20 - loss: 2.7063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:17:01.724062: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 318/4704 [=>............................] - ETA: 1:13:46 - loss: 2.7303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:18:37.763680: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 341/4704 [=>............................] - ETA: 1:13:23 - loss: 2.7266"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ty/sj9j6sl158j5bv97y8pxd76c0000gn/T/ipykernel_92340/2860004640.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        filters_1x1 = filters[0:2] + filters[3:4] + filters[5:]\n",
    "        filters_3x3 = filters[2]\n",
    "        filters_5x5 = filters[4]\n",
    "        self.conv1x1_1 = keras.layers.Conv2D(filters_1x1[0], kernel_size=1, strides=1, padding=\"same\")\n",
    "        self.conv1x1_2 = keras.layers.Conv2D(filters_1x1[1], kernel_size=1, strides=1, padding=\"same\")\n",
    "        self.conv1x1_3 = keras.layers.Conv2D(filters_1x1[2], kernel_size=1, strides=1, padding=\"same\")\n",
    "        self.conv1x1_4 = keras.layers.Conv2D(filters_1x1[3], kernel_size=1, strides=1, padding=\"same\")\n",
    "\n",
    "        self.conv3 = keras.layers.Conv2D(filters_3x3, kernel_size=3, strides=1, padding=\"same\")\n",
    "        self.conv5 = keras.layers.Conv2D(filters_5x5, kernel_size=3, strides=1, padding=\"same\")\n",
    "\n",
    "        self.max_pool = keras.layers.MaxPooling2D(pool_size=3, strides=1, padding=\"same\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z_1 = self.conv1x1_1(inputs)\n",
    "\n",
    "        Z_2 = self.conv1x1_2(inputs)\n",
    "        Z_2 = self.conv3(Z_2)\n",
    "\n",
    "        Z_3 = self.conv1x1_3(inputs)\n",
    "        Z_3 = self.conv5(Z_3)\n",
    "\n",
    "        Z_4 = self.max_pool(inputs)\n",
    "        Z_4 = self.conv1x1_4(Z_4)\n",
    "\n",
    "        return keras.layers.Concatenate(axis=-1)([Z_1, Z_2, Z_3, Z_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            keras.layers.Conv2D(filters, 3, strides=strides, padding=\"samen\", use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters, 3, strides=1, padding=\"same\", use_bias=False),\n",
    "            keras.layers.BatchNormalization()\n",
    "        ]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                keras.layers.Conv2D(filters, kernel_size=1, strides=strides, padding=\"same\", use_bias=False),\n",
    "                keras.layers.BatchNormalization()\n",
    "            ]\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        \n",
    "        return self.activation(skip_Z + Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE_Block(keras.layers.Layer):\n",
    "    def __init__(self, filters, ratio=16):\n",
    "        self.global_avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.squeeze = keras.layers.Dense(filters//ratio, activation='relu')\n",
    "        self.excitation = keras.layers.Dense(filters, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = self.global_avg_pool(inputs)\n",
    "        Z = self.squeeze(Z)\n",
    "        return self.excitation(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XceptionModule(keras.layers.Layer):\n",
    "    def __init__(self, filter):\n",
    "        self.depthwise = keras.layers.Conv2D(filter, kernel_size=3, strides=1, padding='same')\n",
    "        self.pointwise = keras.layers.Conv2D(filter, kernel_size=1, strides=1, padding=\"same\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        Z = self.depthwise(Z)\n",
    "        Z = keras.layers.BatchNormalization()(Z)\n",
    "        Z = self.pointwise(Z)\n",
    "        return keras.layers.BatchNormalization()(Z)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2cd6330df87933e268d4b1d5797575da50d54717d7327a2d2e545dc9a1c6c69"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tf25': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
