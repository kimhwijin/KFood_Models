{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#데이터셋\n",
    "DATASET_NAME = 'kfood'\n",
    "DRIVE_PATH = Path(os.getcwd())\n",
    "DATASET_PATH = DRIVE_PATH / DATASET_NAME\n",
    "filepath = DATASET_PATH\n",
    "print(filepath.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('떡꼬치', '0'), ('편육', '1'), ('후라이드치킨', '2'), ('콩자반', '3'), ('젓갈', '4'), ('양념치킨', '5'), ('과메기', '6'), ('피자', '7'), ('육회', '8'), ('물회', '9'), ('알밥', '10'), ('누룽지', '11'), ('김치볶음밥', '12'), ('김밥', '13'), ('비빔밥', '14'), ('새우볶음밥', '15'), ('유부초밥', '16'), ('잡곡밥', '17'), ('주먹밥', '18'), ('회무침', '19'), ('꽈리고추무침', '20'), ('도라지무침', '21'), ('콩나물무침', '22'), ('홍어무침', '23'), ('잡채', '24'), ('도토리묵', '25'), ('만두', '26'), ('더덕구이', '27'), ('떡갈비', '28'), ('갈비구이', '29'), ('훈제오리', '30'), ('장어구이', '31'), ('삼겹살', '32'), ('불고기', '33'), ('황태구이', '34'), ('조기구이', '35'), ('조개구이', '36'), ('갈치구이', '37'), ('고등어구이', '38'), ('곱창구이', '39'), ('닭갈비', '40'), ('미역줄기볶음', '41'), ('고사리나물', '42'), ('가지볶음', '43'), ('애호박볶음', '44'), ('숙주나물', '45'), ('시금치나물', '46'), ('갈비탕', '47'), ('매운탕', '48'), ('감자탕', '49'), ('추어탕', '50'), ('곰탕_설렁탕', '51'), ('삼계탕', '52'), ('보쌈', '53'), ('육개장', '54'), ('북엇국', '55'), ('콩나물국', '56'), ('무국', '57'), ('계란국', '58'), ('미역국', '59'), ('떡국_만두국', '60'), ('시래기국', '61'), ('간장게장', '62'), ('양념게장', '63'), ('물냉면', '64'), ('수제비', '65'), ('콩국수', '66'), ('막국수', '67'), ('열무국수', '68'), ('비빔냉면', '69'), ('짜장면', '70'), ('쫄면', '71'), ('칼국수', '72'), ('잔치국수', '73'), ('라면', '74'), ('짬뽕', '75'), ('곱창전골', '76'), ('꿀떡', '77'), ('경단', '78'), ('송편', '79'), ('파전', '80'), ('계란말이', '81'), ('동그랑땡', '82'), ('호박전', '83'), ('생선전', '84'), ('김치전', '85'), ('계란후라이', '86'), ('감자전', '87'), ('멍게', '88'), ('산낙지', '89'), ('순대', '90'), ('찜닭', '91'), ('계란찜', '92'), ('닭볶음탕', '93'), ('꼬막찜', '94'), ('김치찜', '95'), ('해물찜', '96'), ('갈비찜', '97'), ('족발', '98'), ('수육', '99'), ('깻잎장아찌', '100'), ('한과', '101'), ('약과', '102'), ('약식', '103'), ('식혜', '104'), ('수정과', '105'), ('라볶이', '106'), ('고추장진미채볶음', '107'), ('멸치볶음', '108'), ('제육볶음', '109'), ('소세지볶음', '110'), ('어묵볶음', '111'), ('건새우볶음', '112'), ('오징어채볶음', '113'), ('두부김치', '114'), ('떡볶이', '115'), ('주꾸미볶음', '116'), ('감자채볶음', '117'), ('코다리조림', '118'), ('갈치조림', '119'), ('감자조림', '120'), ('우엉조림', '121'), ('땅콩조림', '122'), ('메추리알장조림', '123'), ('두부조림', '124'), ('연근조림', '125'), ('장조림', '126'), ('고등어조림', '127'), ('꽁치조림', '128'), ('새우튀김', '129'), ('오징어튀김', '130'), ('고추튀김', '131'), ('깍두기', '132'), ('무생채', '133'), ('나박김치', '134'), ('백김치', '135'), ('오이소박이', '136'), ('갓김치', '137'), ('열무김치', '138'), ('파김치', '139'), ('배추김치', '140'), ('부추김치', '141'), ('총각김치', '142'), ('순두부찌개', '143'), ('김치찌개', '144'), ('된장찌개', '145'), ('동태찌개', '146'), ('닭계장', '147'), ('호박죽', '148'), ('전복죽', '149')])\n"
     ]
    }
   ],
   "source": [
    "#class_label 매칭 딕셔너리로 저장\n",
    "labels = None\n",
    "classes = None\n",
    "with open(filepath / 'class_label.csv','r') as f:\n",
    "    w = csv.reader(f)\n",
    "    classes = w.__next__()\n",
    "    labels = w.__next__()\n",
    "#print(len(classes), len(labels), classes, labels)\n",
    "class_to_label = {}\n",
    "for _class, _label in zip(classes, labels):\n",
    "    class_to_label[_class] = _label\n",
    "\n",
    "print(class_to_label.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150507 150507\n"
     ]
    }
   ],
   "source": [
    "#데이터셋의 이미지 경로 및 레이블 저장\n",
    "from glob import glob\n",
    "image_paths = sorted(glob(\"kfood/*/*/*\"))\n",
    "image_paths = [image_path for image_path in image_paths if image_path.split(\"/\")[-1].split(\".\")[-1].lower() in (\"png\", \"jpg\", \"jpeg\")]\n",
    "labels = [class_to_label[Path(image_path).parent.stem] for image_path in image_paths]\n",
    "print(len(image_paths), len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 생성\n",
    "filenames_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "images_ds = filenames_dataset.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=0)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    print(image)\n",
    "    #image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example['label']\n",
    "\n",
    "def make_kfood_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None, n_parse_threads=5, batch_size=32, cache=True):\n",
    "    filenames_dataset = tf.data.Dataset.from_tensor_slices(filepaths)\n",
    "    images_dataset = filenames_dataset.map(parse_image, num_parallel_calls=n_parse_threads)\n",
    "    cropped_images_dataset = filenames_dataset.map()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "def get_image_paths(filepath, image_formats=(\"*.j*\", \"*.J*\", \"*.png\", \"*.PNG\", \"*.b*\", \"*.B*\", '*.g*', '*.G*')):\n",
    "    paths = []\n",
    "    for image_format in image_formats:\n",
    "        paths += list(filepath.glob(image_format))\n",
    "    return sorted(paths)\n",
    "\n",
    "def get_image_crop_points(filepath):\n",
    "    crops = {}\n",
    "    properties = filepath / \"crop_area.properties\"\n",
    "    with open(properties, 'r') as p:\n",
    "        for row in p:\n",
    "            name, crop = row.replace(\"\\n\", \"\").replace(\" \", \"\").split(\"=\")\n",
    "            if name != \"\" and crop != \"\":\n",
    "                crop = crop.split(\",\")\n",
    "                if len(crop) >= 4:\n",
    "                    crop = [int(crop[1]), int(crop[0]), int(crop[3]), int(crop[2])]\n",
    "                    crops[name] = crop\n",
    "                elif len(crop) == 2:\n",
    "                    crop = [0, 0, int(crop[1]), int(crop[0])]\n",
    "                    crops[name] = crop\n",
    "            \n",
    "    return crops\n",
    "\n",
    "def parse_and_crop_image(filepath):\n",
    "    image = tf.io.read_file(filepath) # 이미지 파일 읽기\n",
    "    print(tf.shape(image))\n",
    "    image_format = Path(filepath).suffix.lower()\n",
    "    if image_format == \".jpg\" or image_format == '.jpeg':\n",
    "        image = tf.image.decode_jpeg(image, channels=3) # JPEG-encoded -> uint8 tensor (RGB format)\n",
    "    elif image_format == '.png':\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "crop_points = {}\n",
    "class_list = list(filepath.glob(\"*/*\"))\n",
    "print(len(class_list))\n",
    "class_list = [class_name for class_name in class_list if class_name.is_dir()]\n",
    "print(len(class_list))\n",
    "for class_name in class_list:\n",
    "    crop_points.update(get_image_crop_points(class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51660"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#{ image_filename : crop_point, ... }\n",
    "len(crop_points.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "images_ds = filenames_dataset.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([], shape=(0,), dtype=int32)\n",
      "tf.Tensor([400 534   3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-24 13:16:07.492231: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-24 13:16:07.492404: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ty/sj9j6sl158j5bv97y8pxd76c0000gn/T/ipykernel_94435/3524824257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtfrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_single_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_descriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_single_example_v2\u001b[0;34m(serialized, features, example_names, name)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"serialized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assert_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"serialized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparse_example_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_example_v2\u001b[0;34m(serialized, features, example_names, name)\u001b[0m\n\u001b[1;32m    312\u001b[0m   ])\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_example_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_construct_tensors_for_composite_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36m_parse_example_raw\u001b[0;34m(serialized, names, params, name)\u001b[0m\n\u001b[1;32m    348\u001b[0m       raise ValueError(\"serialized must have statically-known rank to \"\n\u001b[1;32m    349\u001b[0m                        \"parse ragged features.\")\n\u001b[0;32m--> 350\u001b[0;31m     outputs = gen_parsing_ops.parse_example_v2(\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0mserialized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/ops/gen_parsing_ops.py\u001b[0m in \u001b[0;36mparse_example_v2\u001b[0;34m(serialized, names, sparse_keys, dense_keys, ragged_keys, dense_defaults, num_sparse, sparse_types, ragged_value_types, ragged_split_types, dense_shapes, name)\u001b[0m\n\u001b[1;32m    716\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m       return parse_example_v2_eager_fallback(\n\u001b[0m\u001b[1;32m    719\u001b[0m           \u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mragged_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m           \u001b[0mdense_defaults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/ops/gen_parsing_ops.py\u001b[0m in \u001b[0;36mparse_example_v2_eager_fallback\u001b[0;34m(serialized, names, sparse_keys, dense_keys, ragged_keys, dense_defaults, num_sparse, sparse_types, ragged_value_types, ragged_split_types, dense_shapes, name, ctx)\u001b[0m\n\u001b[1;32m    810\u001b[0m   \u001b[0msparse_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ragged_value_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mragged_value_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m   \"ragged_split_types\", ragged_split_types, \"dense_shapes\", dense_shapes)\n\u001b[0;32m--> 812\u001b[0;31m   _result = _execute.execute(b\"ParseExampleV2\", num_sparse + len(sparse_types)\n\u001b[0m\u001b[1;32m    813\u001b[0m                              \u001b[0;34m+\u001b[0m \u001b[0mnum_sparse\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_defaults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m                              \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mragged_value_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_descriptions = {\n",
    "    \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=0)\n",
    "}\n",
    "for tfrecord in dataset.take(1):\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2cd6330df87933e268d4b1d5797575da50d54717d7327a2d2e545dc9a1c6c69"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tf25': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
